% my fg paper references:

@article{Davis:2006:MHA:1709251.1709302,
 author = {Davis, James W. and Tyagi, Ambrish},
 title = {Minimal-latency Human Action Recognition Using Reliable-inference},
 journal = {Image Vision Comput.},
 issue_date = {May, 2006},
 volume = {24},
 number = {5},
 month = may,
 year = {2006},
 issn = {0262-8856},
 pages = {455--472},
 numpages = {18},
 url = {http://dx.doi.org/10.1016/j.imavis.2006.01.012},
 doi = {10.1016/j.imavis.2006.01.012},
 acmid = {1709302},
 publisher = {Butterworth-Heinemann},
 address = {Newton, MA, USA},
 keywords = {Action recognition, MAP, Reliable-inference, Video analysis},
}

@INPROCEEDINGS{norozi,
author={F. Noroozi and N. Akrami and G. Anbarjafari},
booktitle={2017 25th Signal Processing and Communications Applications Conference (SIU)},
title={Speech-based emotion recognition and next reaction prediction},
year={2017},
volume={},
number={},
pages={1-4},
keywords={emotion recognition;human computer interaction;neural nets;pattern classification;regression analysis;speech recognition;time series;random forest classifier;data-feedback time-series;nonlinear auto-regression time-series neural network;speech signals;emotional reaction prediction system;speech waves;linguistic category;human-computer interaction;next reaction prediction;speech-based emotion recognition;Speech;Feature extraction;Emotion recognition;Databases;Neural networks;Training;Speech recognition;emotion prediction;neural networks;vocal emotion recognition;human-computer interaction},
doi={10.1109/SIU.2017.7960258},
ISSN={},
month={May},}

@inproceedings{Ryoo:2011:HAP:2355573.2356280,
 author = {Ryoo, M. S.},
 title = {Human Activity Prediction: Early Recognition of Ongoing Activities from Streaming Videos},
 booktitle = {Proceedings of the 2011 International Conference on Computer Vision},
 series = {ICCV '11},
 year = {2011},
 isbn = {978-1-4577-1101-5},
 pages = {1036--1043},
 numpages = {8},
 url = {http://dx.doi.org/10.1109/ICCV.2011.6126349},
 doi = {10.1109/ICCV.2011.6126349},
 acmid = {2356280},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
}
@inproceedings{Kwon2003EmotionRB,
  title={Emotion recognition by speech signals},
  author={Oh-Wook Kwon and Kwokleung Chan and Jiucang Hao and Te-Won Lee},
  booktitle={INTERSPEECH},
  year={2003}
}
@inproceedings{Neiberg2006EmotionRI,
  title={Emotion recognition in spontaneous speech using GMMs},
  author={Daniel Neiberg and Kjell Elenius and Kornel Laskowski},
  booktitle={INTERSPEECH},
  year={2006}
}
@ARTICLE{rabi_1,
author={J. {Dubnowski} and R. {Schafer} and L. {Rabiner}},
journal={IEEE Transactions on Acoustics, Speech, and Signal Processing},
title={Real-time digital hardware pitch detector},
year={1976},
volume={24},
number={1},
pages={2-8},
keywords={Hardware;Speech analysis;Detectors;Autocorrelation;Sampling methods;Algorithm design and analysis;Signal analysis;Performance analysis;Logic;Counting circuits},
doi={10.1109/TASSP.1976.1162765},
ISSN={},
month={February},}

@ARTICLE{Sondhi,
author={M. {Sondhi}},
journal={IEEE Transactions on Audio and Electroacoustics},
title={New methods of pitch extraction},
year={1968},
volume={16},
number={2},
pages={262-266},
keywords={Power harmonic filters;Transfer functions;Frequency;Degradation;Speech analysis;Speech synthesis;Band pass filters;Nonlinear distortion;Autocorrelation;Filtering},
doi={10.1109/TAU.1968.1161986},
ISSN={},
month={June},}

@ARTICLE{16,
author={Kenji MASE},
journal={IEICE TRANSACTIONS on Information and Systems},
title={Recognition of Facial Expression from Optical Flow},
year={1991},
volume={E74-D},
number={10},
pages={3474-3483},
month={October},}

@ARTICLE{10,
author={Ekman, P. & Friesen},
journal={Environmental psychology and nonverbal behavior},
title={Measuring facial movement},
year={1976},
volume={1}}

@article{22,
  title={Computing spatio-temporal representations of human faces},
  author={Yaser Yacoob and Larry S. Davis},
  journal={1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition},
  year={1994},
  pages={70-75}
}
@article{21,
 author = {Tian, Ying-li and Kanade, Takeo and Cohn, Jeffrey F.},
 title = {Recognizing Action Units for Facial Expression Analysis},
 journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
 issue_date = {February 2001},
 volume = {23},
 number = {2},
 month = feb,
 year = {2001},
 issn = {0162-8828},
 pages = {97--115},
 numpages = {19},
 url = {https://doi.org/10.1109/34.908962},
 doi = {10.1109/34.908962},
 acmid = {364268},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
 keywords = {AU combinations, Computer vision, action units, facial action coding system, facial expression analysis, multistate face and facial component models, neural network.},
} 
@article{Rosenblatt1958ThePA,
  title={The perceptron: a probabilistic model for information storage and organization in the brain.},
  author={Frank F. Rosenblatt},
  journal={Psychological review},
  year={1958},
  volume={65 6},
  pages={
          386-408
        }
}

@article{Deep_LEarning,
  title={Deep Learning},
  author={Y. LeCun, Y. Bengio, and G. Hinton},
  journal={Nature},
  vol={521},
  year={1994},
  pages={436-444}
}

@inproceedings{g1,
  title={Rate-coded Restricted Boltzmann Machines for Face Recognition},
  author={Yee Whye Teh and Geoffrey E. Hinton},
  booktitle={NIPS},
  year={2000}
}

@article{g2,
 author = {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
 title = {Long Short-Term Memory},
 journal = {Neural Comput.},
 issue_date = {November 15, 1997},
 volume = {9},
 number = {8},
 month = nov,
 year = {1997},
 issn = {0899-7667},
 pages = {1735--1780},
 numpages = {46},
 url = {http://dx.doi.org/10.1162/neco.1997.9.8.1735},
 doi = {10.1162/neco.1997.9.8.1735},
 acmid = {1246450},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
} 

@INPROCEEDINGS {g3,
author = {T. Zhou and M. Brown and N. Snavely and D. G. Lowe},
booktitle = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
title = {Unsupervised Learning of Depth and Ego-Motion from Video},
year = {2017},
volume = {},
issn = {1063-6919},
pages = {6612-6619},
keywords = {cameras;training;pose estimation;three-dimensional displays;geometry;pipelines},
doi = {10.1109/CVPR.2017.700},
url = {https://doi.ieeecomputersociety.org/10.1109/CVPR.2017.700},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {jul}
}
@misc{g4,
    title={Generative Adversarial Networks},
    author={Ian J. Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio},
    year={2014},
    eprint={1406.2661},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}
@article{linnainmaa1970representation,
  title={The representation of the cumulative rounding error of an algorithm as a Taylor expansion of the local rounding errors},
  author={Linnainmaa, Seppo},
  journal={Master's Thesis (in Finnish), Univ. Helsinki},
  pages={6--7},
  year={1970}
}
@article{Bacprop_hinton,
  title={TLearning representations by back-propagating errors},
  author={David E. Rumelhart, Geoffrey E. Hinton & Ronald J. Williams },
  journal={Nature},
  year={1986}
}

@inproceedings{Minsky1969PerceptronsA,
  title={Perceptrons - an introduction to computational geometry},
  author={Marvin Minsky and Seymour Papert},
  year={1969}
}

@ARTICLE{11,
author={I. A. {Essa} and A. P. {Pentland}},
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
title={Coding, analysis, interpretation, and recognition of facial expressions},
year={1997},
volume={19},
number={7},
pages={757-763},
keywords={face recognition;image coding;motion estimation;image sequences;image coding;image analysis;image interpretation;facial expression recognition;computer vision system;facial motion;optimal estimation optical flow method;facial structure;independent muscle action groups;facial action coding system;FACS;FACS+;probabilistic characterization;muscle activation;Face recognition;Computer vision;Motion estimation;Muscles;Humans;Geometrical optics;Nonlinear optics;Image motion analysis;Optical coupling;Solid modeling},
doi={10.1109/34.598232},
ISSN={},
month={July},}
@ARTICLE{markel,
author={J. {Markel}},
journal={IEEE Transactions on Audio and Electroacoustics},
title={The SIFT algorithm for fundamental frequency estimation},
year={1972},
volume={20},
number={5},
pages={367-377},
keywords={Frequency estimation;Autocorrelation;Cepstral analysis;Speech analysis;Digital filters;Testing;Acoustic waves;Filtering algorithms;Algorithm design and analysis;Arithmetic},
doi={10.1109/TAU.1972.1162410},
ISSN={},
month={December},}

@ARTICLE{19,
author={M. {Pantic} and L. J. M. {Rothkrantz}},
journal={Proceedings of the IEEE},
title={Toward an affect-sensitive multimodal human-computer interaction},
year={2003},
volume={91},
number={9},
pages={1370-1390},
keywords={emotion recognition;user interfaces;affect-sensitive multimodal human-computer interaction;emotional intelligence;human intelligence;nonverbal communicative cues;face-to-face interaction;interactive signals;intelligent multimodal HCI;automatic personalized analyzer;Human computer interaction;Emotion recognition;Face detection;Animation;Anthropometry;Neuroscience;Psychology;Cognitive science;Knowledge based systems;Feedback},
doi={10.1109/JPROC.2003.817122},
ISSN={},
month={Sep.},}


@ARTICLE{pitch_rabi,
author={L. {Rabiner} and M. {Cheng} and A. {Rosenberg} and C. {McGonegal}},
journal={IEEE Transactions on Acoustics, Speech, and Signal Processing},
title={A comparative performance study of several pitch detection algorithms},
year={1976},
volume={24},
number={5},
pages={399-418},
keywords={Detection algorithms;Detectors;Measurement standards;Linear predictive coding;Speech;Telephony;Microphones;Wideband;Filtering algorithms;Autocorrelation},
doi={10.1109/TASSP.1976.1162846},
ISSN={},
month={October},}

@INPROCEEDINGS{MMED,
author={M. Hoai and F. De la Torre},
booktitle={2012 IEEE Conference on Computer Vision and Pattern Recognition},
title={Max-margin early event detectors},
year={2012},
volume={},
number={},
pages={2863-2870},
keywords={computer vision;human-robot interaction;object detection;security of data;support vector machines;video signal processing;max-margin early event detectors;temporal events;sequential data;human-robot interaction;video security;structured output SVM;computer vision;Detectors;Training;Time series analysis;Event detection;Humans;Hidden Markov models;Testing},
doi={10.1109/CVPR.2012.6248012},
ISSN={1063-6919},
month={June},}

@inproceedings{Kim2016EmotionSD,
  title={Emotion spotting: discovering regions of evidence in audio-visual emotion expressions},
  author={Yelin Kim and Emily Mower Provost},
  booktitle={ICMI},
  year={2016}
}

@ARTICLE{TayCao,
title = {Application of support vector machines in financial time series forecasting},
author = {Tay, Francis E. H. and Cao, Lijuan},
year = {2001},
journal = {Omega},
volume = {29},
number = {4},
pages = {309-317}}

@ARTICLE{loadForecast,
author={S. J. Kiartzis and C. E. Zoumas and J. B. Theocharis and A. G. Bakirtzis and V. Petridis},
journal={IEEE Transactions on Power Systems},
title={Short-term load forecasting in an autonomous power system using artificial neural networks},
year={1997},
volume={12},
number={4},
pages={1591-1596},
keywords={power system analysis computing;load forecasting;feedforward neural nets;autonomous power system;short-term load forecasting;artificial neural networks;data preparation;network structure definition;temperature sensitivity;computer simulation;daily load curve prediction;Crete;Greece;Load forecasting;Intelligent networks;Power systems;Artificial neural networks;Power system modeling;Temperature;Predictive models;Economic forecasting;Power engineering and energy;Weather forecasting},
doi={10.1109/59.627863},
ISSN={0885-8950},
month={Nov},}

@ARTICLE{bla1,
author={M. Pantic and L. J. M. Rothkrantz},
journal={Proceedings of the IEEE},
title={Toward an affect-sensitive multimodal human-computer interaction},
year={2003},
volume={91},
number={9},
pages={1370-1390},
keywords={emotion recognition;user interfaces;affect-sensitive multimodal human-computer interaction;emotional intelligence;human intelligence;nonverbal communicative cues;face-to-face interaction;interactive signals;intelligent multimodal HCI;automatic personalized analyzer;Human computer interaction;Emotion recognition;Face detection;Animation;Anthropometry;Neuroscience;Psychology;Cognitive science;Knowledge based systems;Feedback},
doi={10.1109/JPROC.2003.817122},
ISSN={0018-9219},
month={Sept},}

@ARTICLE{bla2,
author={R. Cowie and E. Douglas-Cowie and N. Tsapatsoulis and G. Votsis and S. Kollias and W. Fellenz and J. G. Taylor},
journal={IEEE Signal Processing Magazine},
title={Emotion recognition in human-computer interaction},
year={2001},
volume={18},
number={1},
pages={32-80},
keywords={gesture recognition;speech-based user interfaces;speech recognition;psychology;linguistics;emotion recognition;human-computer interaction;implicit messages;signal processing;signal analysis;psychological analyses;linguistic analyses;PKYSTA project;hybrid system;faces;voices;Emotion recognition;Humans;Signal analysis;Psychology;Proposals;Testing;Context;Biomedical signal processing;Face recognition;Speech recognition},
doi={10.1109/79.911197},
ISSN={1053-5888},
month={Jan},}

@ARTICLE{suicide1,
author={R Korrapati and K Nuthalapati and S.Thenmalar, },
journal={International Journal of Pure and Applied Mathematics},
title={A Survey Paper on Suicide Analysis},
year={2018},
volume={118},
number={22},
pages={239-244},
month={Jan},}

@ARTICLE{suicide2,
author={Catherine R. Glenn and Matthew K. Nock},
journal={American journal of preventive medicine},
title={Improving the Short-Term Prediction of Suicidal Behavior},
year={2014},
month={Jan},}

@ARTICLE{psy1,
author={Mindess H},
journal={Journal of Projective Techniques},
title={Predicting Patients' Responses to Psychotherapy: A Preliminary Study Designed to Investigate the Validity of the ‘Rorschach Prognostic Rating Scale.’},
year={1953}}

@ARTICLE{psy2,
author={Hahn T, Kircher T, Straube B, Wittchen HU, Konrad C, Ströhle A, Wittmann A, Pfleiderer B, Reif A, Arolt V, Lueken U},
journal={The Journal of the American Medical Association}
title={Predicting treatment response to cognitive behavioral therapy in panic disorder with agoraphobia by integrating local neural information},
year={2002}}

@ARTICLE{support,
author={Hahn T, Kircher T, Straube B, Wittchen HU, Konrad C, Ströhle A, Wittmann A, Pfleiderer B, Reif A, Arolt V, Lueken U},
journal={Modern Advances in Intelligent Systems and Tools. Studies in Computational Intelligence},
title={A Conversation Model Enabling Intelligent Agents to Give Emotional Support},
year={2012}}

@INPROCEEDINGS{Meta,
author={A. Metallinou and A. Katsamanis and M. W\"ollmer and F. Eyben and B. Schuller and S. Narayanan},
booktitle={2015 International Conference on Affective Computing and Intelligent Interaction (ACII)},
title={Context-sensitive learning for enhanced audiovisual emotion classification (Extended abstract)},
year={2015},
volume={},
number={},
pages={463-469},
doi={10.1109/ACII.2015.7344611},
ISSN={2156-8111},
month={Sept},}

@ARTICLE{IEMOCAP,
author={C. Busso, M. Bulut, C. Lee, A. Kazemzadeh, E. Mower, S. Kim, J. Chang, S. Lee, and S. Narayanan},
journal={Journal of Language Resources and Evaluation},
title={IEMOCAP: Interactive emotional dyadic motion capture database},
year={2015},
volume={42},
number={4},
pages={335-359},
month={Dec}}

@INPROCEEDINGS{Meta2,
author={M. W\"ollmer and A. Metallinou and N. Katsamanis and B. Schuller and S. Narayanan},
booktitle={2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
title={Analyzing the memory of BLSTM Neural Networks for enhanced emotion classification in dyadic spoken interactions},
year={2012},
volume={},
number={},
pages={4157-4160},
keywords={emotion recognition;recurrent neural nets;speech recognition;BLSTM neural network memory;bidirectional long short term memory;recurrent neural network;enhanced emotion classification;dyadic spoken interaction;automatic emotion recognition systems;contextual information;utterance level observation;Context;Emotion recognition;Feature extraction;Recurrent neural networks;Hidden Markov models;Context modeling;emotion recognition;Long Short-Term Memory;sequential Jacobian;context modeling},
doi={10.1109/ICASSP.2012.6288834},
ISSN={2379-190X},
month={March},}

@article{praat,
author = {Boersma, Paul and Weenink, David},
year = {2007},
month = {01},
pages = {},
title = {PRAAT: Doing phonetics by computer (Version 5.3.51)}
}

@INPROCEEDINGS{fu,
author={L. Fu and X. Mao and L. Chen},
booktitle={2008 IEEE Pacific-Asia Workshop on Computational Intelligence and Industrial Application},
title={Relative Speech Emotion Recognition Based Artificial Neural Network},
year={2008},
volume={2},
number={},
pages={140-144},
keywords={emotion recognition;feature extraction;neural nets;speech recognition;speech emotion recognition;artificial neural network;normalized temporal features vector;static features vector;Emotion recognition;Artificial neural networks;Spatial databases;Shape;Hidden Markov models;Speech recognition;Loudspeakers;Humans;Automatic speech recognition;Acoustic distortion;speech emotion recognition;relative features;ANN},
doi={10.1109/PACIIA.2008.355},
ISSN={},
month={Dec},}

@INPROCEEDINGS{face1,
author={J. G. Rázuri and D. Sundgren and R. Rahmani and A. M. Cardenas},
booktitle={2013 12th Mexican International Conference on Artificial Intelligence},
title={Automatic Emotion Recognition through Facial Expression Analysis in Merged Images Based on an Artificial Neural Network},
year={2013},
volume={},
number={},
pages={85-96},
keywords={backpropagation;emotion recognition;face recognition;feedforward neural nets;image classification;image fusion;object detection;automatic human emotion recognition;facial expression analysis;merged image;artificial neural network;human face detection;facial emotions;social skills;socially intelligent systems;information classification technique;image fusion;emotional expression decoding;feed-forward neural network;back-propagation;training set time reduction;emotion detection;Emotion recognition;Face;Feature extraction;Artificial neural networks;Neurons;Face recognition;Artificial Neural Network;Merged Images;Facial Expression Recognition;Emotions;Detection of Emotional Information},
doi={10.1109/MICAI.2013.16},
ISSN={},
month={Nov},}

@INPROCEEDINGS{face2,
author={G. UKharat and S. V. Dud ul},
booktitle={2008 Conference on Human System Interactions},
title={Emotion recognition from facial expression using neural networks},
year={2008},
volume={},
number={},
pages={422-427},
keywords={emotion recognition;face recognition;humanoid robots;neural nets;robot vision;emotion recognition;facial expression;neural networks;mind implemented robot;Emotion recognition;Training;Principal component analysis;Face recognition;Artificial neural networks;Feature extraction;Discrete cosine transforms;Multilayer Perceptron (MLP);Principal Component Analysis (PCA);Generalized Feed Forward Neural Network (GFFNN);Features Extraction},
doi={10.1109/HSI.2008.4581476},
ISSN={2158-2246},
month={May},}

@ARTICLE{LSTM,
author={S. Hochreiter and J. Schmidhuber},
journal={Neural Computation},
title={Long Short-Term Memory},
year={1997},
volume={9},
number={8},
pages={1735-1780},
keywords={},
doi={10.1162/neco.1997.9.8.1735},
ISSN={0899-7667},
month={Nov},}
@inproceedings{Mutual,
	address = {Brighton, UK},
	title = {Modeling {Mutual} {Influence} of {Interlocutor} {Emotion} {States} in {Dyadic} {Spoken} {Interactions}},
	url = {http://ict.usc.edu/pubs/Modeling%20Mutual%20Influence%20of%20Interlocutor%20Emotion%20States%20in%20Dyadic%20Spoken%20Interactions.pdf},
	abstract = {In dyadic human interactions, mutual influence - a person's in- fluence on the interacting partner's behaviors - is shown to be important and could be incorporated into the modeling frame- work in characterizing, and automatically recognizing the par- ticipants' states. We propose a Dynamic Bayesian Network (DBN) to explicitly model the conditional dependency between two interacting partners' emotion states in a dialog using data from the IEMOCAP corpus of expressive dyadic spoken in- teractions. Also, we focus on automatically computing the Valence-Activation emotion attributes to obtain a continuous characterization of the participants' emotion flow. Our pro- posed DBN models the temporal dynamics of the emotion states as well as the mutual influence between speakers in a dialog. With speech based features, the proposed network improves classification accuracy by 3.67\% absolute and 7.12\% relative over the Gaussian Mixture Model (GMM) baseline on isolated turn-by-turn emotion classification.},
	booktitle = {Proceedings of {Interspeech} 2009},
	author = {Lee, Chi-Chun and Busso, Carlos and Lee, Sungbok and Narayanan, Shrikanth},
	month = sep,
	year = {2009}
}

@article{adam,
  title={Adam: A Method for Stochastic Optimization},
  author={Diederik P. Kingma and Jimmy Ba},
  journal={CoRR},
  year={2014},
  volume={abs/1412.6980}
}

@INPROCEEDINGS{pattern,
author={T. Yamada and H. Hashimoto and N. Tosa},
booktitle={Proceedings of IECON '95 - 21st Annual Conference on IEEE Industrial Electronics},
title={Pattern recognition of emotion with neural network},
year={1995},
volume={1},
number={},
pages={183-187 vol.1},
keywords={neural nets;speech recognition;human factors;behavioural sciences;learning (artificial intelligence);behavioural sciences computing;emotion model;pattern recognition;human communication;neural network;personality;character information;learning;input voice signals;response;sadness;cheerfulness;happiness;anger;Network Neuro-Baby;Pattern recognition;Neural networks;Emotion recognition;Humans;Speech recognition;Monitoring;Character generation;Face recognition;Education;Petroleum},
doi={10.1109/IECON.1995.483355},
ISSN={},
month={Nov},}

@INPROCEEDINGS{chatbot,
author={Dongkeon Lee and Kyo-Joong Oh and Ho-Jin Choi},
booktitle={2017 IEEE International Conference on Big Data and Smart Computing (BigComp)},
title={The chatbot feels you - a counseling service using emotional response generation},
year={2017},
volume={},
number={},
pages={437-440},
keywords={emotion recognition;ethical aspects;health care;natural language processing;psychology;drinking habit;intervene chatbot;continuous emotion recognition;mental healthcare experiment;clinical psychiatric consolation;psychiatric counseling service;natural language processing;conversation content;NLP;emotional flow;continuous conversation observation;personalized counseling response;user input;user emotion;expected reaction;ethical view;emotional response generation;Emotion recognition;Employee welfare;Medical services;Context;Natural language processing;Data models;Probabilistic logic;conversational service;response generation;deep learning},
doi={10.1109/BIGCOMP.2017.7881752},
ISSN={2375-9356},
month={Feb},}

@manual{siri,
       title="Siri",
      note   = "\url{https://www.apple.com/siri/}",
      year   = "accessed September 22, 2018"
    }
    
    @manual{alexa,
       title="Amazon Alexa",
      note   = "\url{https://developer.amazon.com/alexa}",
      year   = "accessed September 22, 2018"
    }
    
    
@inproceedings{fig1,
  title={Scripted dialogs versus improvisation: lessons learned about emotional elicitation techniques from the IEMOCAP database},
  author={Carlos Busso and Shrikanth Narayanan},
  booktitle={INTERSPEECH},
  year={2008}
}
@inproceedings{fig2,
  title={Movie Recommendation via BLSTM},
  author={Song Tang, Zhiyong Wu, Kang Chen},
  booktitle={International Conference on Multimedia Modeling},
  year={2016}
}
@INPROCEEDINGS{baltru,
author={T. Baltrušaitis and N. Banda and P. Robinson},
booktitle={2013 10th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG)},
title={Dimensional affect recognition using Continuous Conditional Random Fields},
year={2013},
volume={},
number={},
pages={1-8},
keywords={emotion recognition;random processes;regression analysis;support vector machines;audio feature;geometric shape;emotion dimension;correlation aware continuous conditional random field;continuous emotion;SVR;support vector machines for regression;continuous dimensional space;emotion classification;multimodal signal;emotion automatic recognition;nonverbal speech;head pose;posture;facial expression;nonverbal signal;interaction people display;continuous conditional random fields;dimensional affect recognition;Feature extraction;Emotion recognition;Shape;Predictive models;Face;Vectors;Support vector machines},
doi={10.1109/FG.2013.6553785},
ISSN={},
month={April},}

@misc{keras,
  title={Keras},
  author={Chollet, Fran\c{c}ois and others},
  year={2015},
  howpublished={\url{https://keras.io}},
}
@INPROCEEDINGS{speech_rec,
author={W. Chan and N. Jaitly and Q. Le and O. Vinyals},
booktitle={2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
title={Listen, attend and spell: A neural network for large vocabulary conversational speech recognition},
year={2016},
volume={},
number={},
pages={4960-4964},
keywords={channel bank filters;decoding;encoding;hidden Markov models;neural net architecture;recurrent neural nets;speech coding;speech recognition;statistical distributions;neural network;large vocabulary conversational speech recognition;listen-attend and spell neural speech recognizer;LAS;speech utterances;neural network architecture;language models;CTC;probability distribution;output character sequences;acoustic sequence;pyramidal recurrent network encoder;filter bank spectra;attention-based recurrent network decoder;Google voice search task;CLDNN-HMM model;end-to-end trained system;end-to-end model;Hidden Markov models;Speech recognition;Acoustics;Speech;Decoding;Training;Context;Recurrent neural network;neural attention;end-to-end speech recognition},
doi={10.1109/ICASSP.2016.7472621},
ISSN={2379-190X},
month={March},}

 @InProceedings{action,
author = {Du, Yong and Wang, Wei and Wang, Liang},
title = {Hierarchical Recurrent Neural Network for Skeleton Based Action Recognition},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2015}
}

@ARTICLE{significance,
author={T. G. Dietterich},
journal={Neural Computation},
title={Approximate Statistical Tests for Comparing Supervised Classification Learning Algorithms},
year={1998},
volume={10},
number={7},
pages={1895-1923},
keywords={},
doi={10.1162/089976698300017197},
ISSN={0899-7667},
month={Oct},}


@INPROCEEDINGS{kim_icassp_2013,
author={Y. Kim and E. M. Provost},
booktitle={2013 IEEE International Conference on Acoustics, Speech and Signal Processing},
title={Emotion classification via utterance-level dynamics: A pattern-based approach to characterizing affective expressions},
year={2013},
volume={},
number={},
pages={3677-3681},
keywords={emotion recognition;motion estimation;time series;time warp simulation;emotion classification;utterance level dynamics;pattern based approach;affective expressions;human emotion;affective communication;automatic emotion recognition;emotional assessments;emotion flow;short time affective characteristics;time series estimates;dynamic time warping;feature based baseline;static modeling;emotion expression;Hidden Markov models;Accuracy;Trajectory;Emotion recognition;Speech;Mathematical model;Speech recognition;emotion classification;emotion dynamics;emotion structure;multimodal;dynamic time warping;dynamic pattern},
doi={10.1109/ICASSP.2013.6638344},
ISSN={1520-6149},
month={May},}

% end of my fg paper ref.
@ARTICLE{bla2,
author={R. Cowie and E. Douglas-Cowie and N. Tsapatsoulis and G. Votsis and S. Kollias and W. Fellenz and J. G. Taylor},
journal={IEEE Signal Processing Magazine},
title={Emotion recognition in human-computer interaction},
year={2001},
volume={18},
number={1},
pages={32-80},
keywords={gesture recognition;speech-based user interfaces;speech recognition;psychology;linguistics;emotion recognition;human-computer interaction;implicit messages;signal processing;signal analysis;psychological analyses;linguistic analyses;PKYSTA project;hybrid system;faces;voices;Emotion recognition;Humans;Signal analysis;Psychology;Proposals;Testing;Context;Biomedical signal processing;Face recognition;Speech recognition},
doi={10.1109/79.911197},
ISSN={1053-5888},
month={Jan},}

@ARTICLE{bla1,
author={M. Pantic and L. J. M. Rothkrantz},
journal={Proceedings of the IEEE},
title={Toward an affect-sensitive multimodal human-computer interaction},
year={2003},
volume={91},
number={9},
pages={1370-1390},
keywords={emotion recognition;user interfaces;affect-sensitive multimodal human-computer interaction;emotional intelligence;human intelligence;nonverbal communicative cues;face-to-face interaction;interactive signals;intelligent multimodal HCI;automatic personalized analyzer;Human computer interaction;Emotion recognition;Face detection;Animation;Anthropometry;Neuroscience;Psychology;Cognitive science;Knowledge based systems;Feedback},
doi={10.1109/JPROC.2003.817122},
ISSN={0018-9219},
month={Sept},}

@ARTICLE{suicide2,
author={Catherine R. Glenn and Matthew K. Nock},
journal={American journal of preventive medicine},
title={Improving the Short-Term Prediction of Suicidal Behavior},
year={2014},
month={Jan},}

@ARTICLE{suicide1,
author={R Korrapati and K Nuthalapati and S.Thenmalar, },
journal={International Journal of Pure and Applied Mathematics},
title={A Survey Paper on Suicide Analysis},
year={2018},
volume={118},
number={22},
pages={239-244},
month={Jan},}

@ARTICLE{psy1,
author={Mindess H},
journal={Journal of Projective Techniques},
title={Predicting Patients' Responses to Psychotherapy: A Preliminary Study Designed to Investigate the Validity of the ‘Rorschach Prognostic Rating Scale.’},
year={1953}}

@ARTICLE{psy2,
author={Hahn T, Kircher T, Straube B, Wittchen HU, Konrad C, Ströhle A, Wittmann A, Pfleiderer B, Reif A, Arolt V, Lueken U},
journal={The Journal of the American Medical Association},
title={Predicting treatment response to cognitive behavioral therapy in panic disorder with agoraphobia by integrating local neural information},
year={2002}}

@manual{siri,
       title="Siri",
      note   = "\url{https://www.apple.com/siri/}",
      year   = "accessed September 22, 2018"
    }
    
@manual{alexa,
       title="Amazon Alexa",
      note   = "\url{https://developer.amazon.com/alexa}",
      year   = "accessed September 22, 2018"
    }






%From priti
@INPROCEEDINGS{Priti, 
author  = {P. G. {Pachpande} and M. H. {Khadr} and A. F. {Hussein} and H. {Elgala}}, 
booktitle = {"IEEE 39th Sarnoff Symposium"}, 
title = {"Visible light communication using deep learning techniques"}, 
year={2018}, 
pages={563-575}, 
keywords={Deep Learning; autoencoder; quadrature amplitude modulation; visible light communications.}, 
doi={}, 
ISSN={}, 
month={Sept.},}


@article{VLC,
author = {Ghassemlooy, Zabih and Zvanovec, Stanislav and Khalighi, Mohammad-Ali and , M-A and Popoola, Wasiu and O, W and Perez, Joaquin},
year = {2017},
month = {12},
pages = {1-6},
title = {Optical wireless communication systems},
volume = {151},
journal = {Optik - International Journal for Light and Electron Optics},
doi = {10.1016/j.ijleo.2017.11.052}
}
@book{eqn,
  added-at = {2009-04-20T21:27:16.000+0200},
  at = {2008-03-31 06:17:47},
  author = {Cover, Thomas M. and Thomas, Joy A.},
  biburl = {https://www.bibsonomy.org/bibtex/22e9bfa879286689a14feb55b69d326c1/ywhuang},
  howpublished = {Hardcover},
  id = {1877660},
  interhash = {87ae368776946bf7a71ee476e81a2191},
  intrahash = {2e9bfa879286689a14feb55b69d326c1},
  isbn = {0471241954},
  keywords = {information-theory book},
  month = {July},
  priority = {0},
  publisher = {Wiley-Interscience},
  timestamp = {2009-04-20T21:27:16.000+0200},
  title = {Elements of Information Theory (Wiley Series in Telecommunications and Signal Processing, 2^{nd} Edition )},
  year = {2006},
}
@article{AE,
  author    = {Timothy J. O'Shea and
               Kiran Karra and
               T. Charles Clancy},
  title     = {Learning to Communicate: Channel Auto-encoders, Domain Specific Regularizers,
               and Attention},
  journal   = {CoRR},
  volume    = {abs/1608.06409},
  year      = {2016},
  url       = {http://arxiv.org/abs/1608.06409},
  archivePrefix = {arXiv},
  eprint    = {1608.06409},
  timestamp = {Mon, 13 Aug 2018 16:49:05 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/OSheaKC16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{Shea, 
author  = {T. {O'Shea} and J. {Hoydis}}, 
journal = {"IEEE Transactions on Cognitive Communications and Networking"}, 
title = {"An Introduction to Deep Learning for the Physical Layer"}, 
year={2017}, 
volume={3}, 
number={4}, 
pages={563-575}, 
keywords={computer networks;convolution;feedforward neural nets;learning (artificial intelligence);open systems;optimisation;receivers;deep learning;physical layer;communications system design;end-to-end reconstruction task;receiver components;multiple transmitters;radio transformer networks;expert domain knowledge;machine learning model;convolutional neural networks;autoencoder;joint optimisation;transmitter components;modulation classification;Artificial neural networks;Physical layer;Communication systems;Receivers;Modulation;Radio transmitters;Machine learning;Machine learning;deep learning;physical layer;digital communications;modulation;radio communication;cognitive radio}, 
doi={10.1109/TCCN.2017.2758370}, 
ISSN={2332-7731}, 
month={Dec},}




@ARTICLE{OFDM, 
author={M. {Kim} and W. {Lee} and D. {Cho}}, 
journal={IEEE Communications Letters}, 
title={{A Novel PAPR Reduction Scheme for OFDM System Based on Deep Learning}}, 
year={2018}, 
volume={22}, 
number={3}, 
pages={510-513}, 
keywords={error statistics;learning (artificial intelligence);neural net architecture;OFDM modulation;telecommunication computing;novel PAPR reduction scheme;PRNet;constellation mapping;deep learning technique;peak-to-average power ratio;orthogonal frequency division multiplexing system;OFDM systems;PAPR reducing network;autoencoder architecture;symbol demapping;bit error rate;BER;Peak to average power ratio;Machine learning;Decoding;Bit error rate;Nonlinear distortion;Orthogonal frequency division multiplexing;autoencoder;deep learning;peak-to-average power ratio}, 
doi={10.1109/LCOMM.2017.2787646}, 
ISSN={1089-7798}, 
month={March},}

@article{sigmoid,
author = {Hoon Lee and Inkyu Lee and Tony Q. S. Quek and Sang Hyun Lee},
journal = {Opt. Express},
keywords = {Optical communications; Light-emitting diodes; Illumination design ; Color; Modulation techniques; Optical signals; Optical wireless communication; Orthogonal frequency division multiplexing; Stochastic gradient descent; Visible light},
number = {14},
pages = {18131--18142},
publisher = {OSA},
title = {Binary signaling design for visible light communication: a deep learning framework},
volume = {26},
month = {Jul},
year = {2018},
url = {http://www.opticsexpress.org/abstract.cfm?URI=oe-26-14-18131},
doi = {10.1364/OE.26.018131},
}



@inproceedings{MIMO,
author = {Soltani, Morteza and Fatnassi, Wael and Aboutaleb, Ahmed and Rezki, Zouheir and Bhuyan, Arup and E. Titus, Paul},
year = {2018},
month = {09},
title = {Autoencoder-Based Optical Wireless Communications},
doi = {10.1109/GLOCOMW.2018.8644104},
}
@MISC{neuron,
author = {Ujjwal, Karn},
title = {A Quick Introduction to Neural Networks},
month = {Aug},
year = {2016},
howpublished={\url{https://ujjwalkarn.me/2016/08/09/quick-intro-neural-networks/}}}



@MISC{uwb,
author = { P. G. {Pachpande} and H. {Elgala} and  G. B. {Burke}},
title = {Intelligent Transportation based UWB Positioning and Connectivity },
month = {Sept},
year = {2017},
howpublished={\url{https://drive.google.com/file/d/1CMMbG59X_CqECbG8qD6_ju-KtJ4APWnG/view?usp=sharing}}}

@ARTICLE{bit1, 
author={H. {Qian} and J. {Chen} and S. {Yao} and Z. Y. {Zhang} and H. {Zhang} and W. {Xu}}, 
journal={IEEE Photonics Technology Letters}, 
title={One-Bit Sigma-Delta Modulator for Nonlinear Visible Light Communication Systems}, 
year={2015}, 
volume={27}, 
number={4}, 
pages={419-422}, 
keywords={amplitude shift keying;filtering theory;LED lamps;optical communication equipment;optical modulation;sigma-delta modulation;one-bit sigma-delta modulator;one-bit SDM;nonlinear visible light communication systems;VLC system;modulation bandwidth;light emitting diode;spectral efficiency;modulation schemes;peak-to-average power ratio;LED lighting systems;LED drivers;on-off keying signal;quantization noise;analog filtering;digital signal processing;Light emitting diodes;Modulation;Noise;Peak to average power ratio;Bit error rate;Quantization (signal);Bandwidth;Visible light communications;nonlinearity;Sigma-delta modulator;Visible light communications;nonlinearity;sigma-delta modulator}, 
doi={10.1109/LPT.2014.2376971}, 
ISSN={1041-1135}, 
month={Feb},}

@ARTICLE{bit2, 
author={H. {Qian} and J. {Chen} and S. {Yao} and Z. Y. {Zhang} and H. {Zhang} and W. {Xu}}, 
journal={IEEE Photonics Technology Letters}, 
title={One-Bit Sigma-Delta Modulator for Nonlinear Visible Light Communication Systems}, 
year={2015}, 
volume={27}, 
number={4}, 
pages={419-422}, 
keywords={amplitude shift keying;filtering theory;LED lamps;optical communication equipment;optical modulation;sigma-delta modulation;one-bit sigma-delta modulator;one-bit SDM;nonlinear visible light communication systems;VLC system;modulation bandwidth;light emitting diode;spectral efficiency;modulation schemes;peak-to-average power ratio;LED lighting systems;LED drivers;on-off keying signal;quantization noise;analog filtering;digital signal processing;Light emitting diodes;Modulation;Noise;Peak to average power ratio;Bit error rate;Quantization (signal);Bandwidth;Visible light communications;nonlinearity;Sigma-delta modulator;Visible light communications;nonlinearity;sigma-delta modulator}, 
doi={10.1109/LPT.2014.2376971}, 
ISSN={1041-1135}, 
month={Feb},}
